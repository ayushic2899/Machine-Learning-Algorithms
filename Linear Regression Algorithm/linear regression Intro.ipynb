{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the easiest and most popular Machine Learning algorithms. It is a statistical method that is used for predictive analysis. Linear regression makes predictions for continuous/real or numeric variables such as sales, salary, age, product price, etc.\n",
    "\n",
    "Linear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) variables, hence called as linear regression. Since linear regression shows the linear relationship, which means it finds how the value of the dependent variable is changing according to the value of the independent variable.\n",
    "\n",
    "The linear regression model provides a sloped straight line representing the relationship between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we can represent a linear regression as:\n",
    "\n",
    "#### y= a0+a1x+ ε"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Y= Dependent Variable (Target Variable)\n",
    "##### X= Independent Variable (predictor Variable)\n",
    "##### a0= intercept of the line (Gives an additional degree of freedom)\n",
    "##### a1 = Linear regression coefficient (scale factor to each input value).\n",
    "##### ε = random error\n",
    "\n",
    "The values for x and y variables are training datasets for Linear Regression model representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Linear Regression\n",
    "Linear regression can be further divided into two types of the algorithm:\n",
    "\n",
    "##### Simple Linear Regression:\n",
    "If a single independent variable is used to predict the value of a numerical dependent variable, then such a Linear Regression algorithm is called Simple Linear Regression.\n",
    "##### Multiple Linear regression:\n",
    "If more than one independent variable is used to predict the value of a numerical dependent variable, then such a Linear Regression algorithm is called Multiple Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Line\n",
    "A linear line showing the relationship between the dependent and independent variables is called a regression line. A regression line can show two types of relationship:\n",
    "\n",
    "#### Positive Linear Relationship:\n",
    "If the dependent variable increases on the Y-axis and independent variable increases on X-axis, then such a relationship is termed as a Positive linear relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Linear Relationship:\n",
    "If the dependent variable decreases on the Y-axis and independent variable increases on the X-axis, then such a relationship is called a negative linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best fit line:\n",
    "When working with linear regression, our main goal is to find the best fit line that means the error between predicted values and actual values should be minimized. The best fit line will have the least error.\n",
    "\n",
    "The different values for weights or the coefficient of lines (a0, a1) gives a different line of regression, so we need to calculate the best values for a0 and a1 to find the best fit line, so to calculate this we use cost function.\n",
    "\n",
    "### Cost function-\n",
    "The different values for weights or coefficient of lines (a0, a1) gives the different line of regression, and the cost function is used to estimate the values of the coefficient for the best fit line.\n",
    "Cost function optimizes the regression coefficients or weights. It measures how a linear regression model is performing.\n",
    "We can use the cost function to find the accuracy of the mapping function, which maps the input variable to the output variable. This mapping function is also known as Hypothesis function.\n",
    "For Linear Regression, we use the Mean Squared Error (MSE) cost function, which is the average of squared error occurred between the predicted values and actual values. It can be written as:\n",
    "\n",
    "https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning4.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals: \n",
    "The distance between the actual value and predicted values is called residual. If the observed points are far from the regression line, then the residual will be high, and so cost function will high. If the scatter points are close to the regression line, then the residual will be small and hence the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent:\n",
    "Gradient descent is used to minimize the MSE by calculating the gradient of the cost function.\n",
    "A regression model uses gradient descent to update the coefficients of the line by reducing the cost function.\n",
    "It is done by a random selection of values of coefficient and then iteratively update the values to reach the minimum cost function.\n",
    "#### Model Performance:\n",
    "The Goodness of fit determines how the line of regression fits the set of observations. The process of finding the best model out of various models is called optimization. It can be achieved by below method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. R-squared method:\n",
    "\n",
    "1. R-squared is a statistical method that determines the goodness of fit.\n",
    "2. It measures the strength of the relationship between the dependent and independent variables on a scale of 0-100%.\n",
    "3. The high value of R-square determines the less difference between the predicted values and actual values and hence represents a good model.\n",
    "4. It is also called a coefficient of determination, or coefficient of multiple determination for multiple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Are the Basic Assumption?(favourite)\n",
    "There are four assumptions associated with a linear regression model:\n",
    "\n",
    "1. Linearity: The relationship between X and the mean of Y is linear.\n",
    "2. Homoscedasticity: The variance of residual is the same for any value of X.\n",
    "3. Independence: Observations are independent of each other.\n",
    "4. Normality: For any fixed value of X, Y is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "1. Linear regression performs exceptionally well for linearly separable data\n",
    "2. Easy to implement and train the model\n",
    "3. It can handle overfitting using dimensionlity reduction techniques and cross validation and regularization\n",
    "### Disadvantages\n",
    "1. Sometimes Lot of Feature Engineering Is required\n",
    "2. If the independent features are correlated it may affect performance\n",
    "3. It is often quite prone to noise and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whether Feature Scaling is required?\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact of Missing Values?\n",
    "It is sensitive to missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Problems it can solve(Supervised)\n",
    "Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Problem statement you can solve using Linear Regression\n",
    "1. Advance House Price Prediction\n",
    "2. Flight Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
